{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import ConvBertTokenizer, TFConvBertModel\n",
    "\n",
    "from model import bert_bigru_cnn_model, bert_bilstm_attention_model, bert_bilstm_model\n",
    "from train_model import train_model, fetch_results\n",
    "from test import *\n",
    "from data import create_tensor_dataset, create_test_dataset\n",
    "from text_cleaning import clean_text\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *\n",
    "import gc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Yükleme ve Modele Hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLUMN = 'number_to_text'\n",
    "LABEL_COLUMN = 'label'\n",
    "MAX_LENGTH = 32\n",
    "BATCH_SIZE = 256 # 128\n",
    "MODEL_NAME = 'dbmdz/convbert-base-turkish-mc4-uncased'\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/augmented_train.csv')\n",
    "valid_df = pd.read_csv('./data/cleaned_valid_df.csv')\n",
    "test_df = pd.read_csv('./data/cleaned_test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing -- default: 'text' column\n",
    "train_df = clean_text(train_df)\n",
    "valid_df = clean_text(valid_df)\n",
    "test_df = clean_text(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERİ ARTIRIMI (DATA AUGMENTATION) SONRASI OLUŞABİLECEK DUPLICATE SORUNUNU GİDERME\n",
    "def remove_common_rows(df1, df2):\n",
    "\tcommon_train_valid = set(df1[TEXT_COLUMN]).intersection(set(df2[TEXT_COLUMN].values.tolist()))\n",
    "\tix = df1[df1[TEXT_COLUMN].isin(common_train_valid)].index\n",
    "\tdf1 = df1.drop(ix)\n",
    "\treturn df1\n",
    "\n",
    "train_df = remove_common_rows(train_df, valid_df)\n",
    "train_df = remove_common_rows(train_df, test_df)\n",
    "valid_df = remove_common_rows(valid_df, test_df)\n",
    "\n",
    "# drop duplicates\n",
    "train_df = train_df.drop_duplicates()\n",
    "valid_df = valid_df.drop_duplicates()\n",
    "test_df = test_df.drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATE BATCH DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tokenizer\n",
    "tokenizer = ConvBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# prepare train, valid and test tensor datasets from data.py\n",
    "train_dataset, dev_dataset = create_tensor_dataset(train_df, valid_df, tokenizer, 'number_to_text', 'label', max_length=MAX_LENGTH)\n",
    "\n",
    "# batches or not --> batch dataset: test_dataset\n",
    "test_dataset, test_encoded = create_test_dataset(test_df.number_to_text.values, tokenizer, max_length=MAX_LENGTH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load convbert-base-base-turkish-mc4-uncased model\n",
    "bert_encoder = TFConvBertModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE 3 DIFFERENT MODELS\n",
    "bert_bilstm_net = bert_bilstm_model(bert_encoder, max_length=MAX_LENGTH)\n",
    "bert_bigru_cnn_net = bert_bigru_cnn_model(bert_encoder, max_length=MAX_LENGTH)\n",
    "bert_bilstm_attention_net = bert_bilstm_attention_model(bert_encoder, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING A MODEL\n",
    "train_model(bert_bilstm_net, train_dataset, dev_dataset, batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
    "#train_model(bert_bigru_cnn_net, train_dataset, dev_dataset, batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
    "#train_model(bert_bilstm_attention_net, train_dataset, dev_dataset, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show performance results on dev dataset\n",
    "prediction, outputs = fetch_results(bert_bilstm_net, dev_dataset=dev_dataset, true_labels=valid_df.label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WITH STRATIFIEDKFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df[[TEXT_COLUMN, LABEL_COLUMN]], valid_df[[TEXT_COLUMN, LABEL_COLUMN]]])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "X = df[TEXT_COLUMN]\n",
    "Y = df[LABEL_COLUMN]\n",
    "\n",
    "test_dataset, test_encoded = create_test_dataset(test_df[TEXT_COLUMN].values, tokenizer, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skf.get_n_splits(X, Y)\n",
    "fold_num = 0\n",
    "models = []\n",
    "oof = 0\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "\tfold_num+=1\n",
    "\tprint(\"Results for fold\",fold_num)\n",
    "\tx_train, x_val = X.iloc[train_index], X.iloc[val_index]\n",
    "\ty_train, y_val = Y.iloc[train_index], Y.iloc[val_index]\n",
    "\n",
    "\ttemp_train = pd.concat([x_train, y_train], axis=1)\n",
    "\ttemp_valid = pd.concat([x_val, y_val], axis=1)\n",
    "\ttrain_dataset, dev_dataset = create_tensor_dataset(temp_train, temp_valid, tokenizer, TEXT_COLUMN, LABEL_COLUMN, max_length=MAX_LENGTH)\n",
    "\n",
    "\tmodel = bert_bilstm_model(bert_encoder, max_length=MAX_LENGTH)\n",
    "\ttrain_model(model, train_dataset, dev_dataset, batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
    "\tmodels.append(model)\n",
    "\tvalid_pred = model.predict(dev_dataset)\n",
    "\tf1 = f1_score(y_val, np.argmax(valid_pred, 1), average='macro')\n",
    "\tprint(f'{fold_num}. FOLD TEST F1 SCORE: {f1}')\n",
    "\n",
    "\ttest_pred = model.predict(test_dataset)\n",
    "\toof += test_pred\n",
    "\t\n",
    "\tdel temp_train, temp_valid, model\n",
    "\tgc.collect()\n",
    " \n",
    "bert_bilstm_test_predictions = np.argmax(oof/5, 1)\n",
    "# bert_bigru_cnn_test_predictions = np.argmax(oof/5, 1)\n",
    "# bert_bilstm_attention_test_predictions = np.argmax(oof/5, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE 3 DIFFERENT KFOLD MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show performance results on test dataset\n",
    "#prediction_bert_bilstm, outputs_bert_bilstm = fetch_results(bert_bilstm_net, dev_dataset=test_dataset, true_labels=None)\n",
    "#prediction_bert_bigru_cnn, outputs_bert_bigru_cnn = fetch_results(bert_bigru_cnn_net, dev_dataset=test_dataset, true_labels=None)\n",
    "#prediction_bert_bilstm_attention, outputs_bert_bilstm_attention = fetch_results(bert_bilstm_attention_net, dev_dataset=test_dataset, true_labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble = 0.39 * bert_bilstm_test_predictions +  0.38 * bert_bigru_cnn_test_predictions + 0.23 * bert_bilstm_attention_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
